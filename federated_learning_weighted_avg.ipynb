{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T20:45:23.632085Z",
     "start_time": "2024-11-09T20:45:01.496632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "\n",
    "RND_SEED = 0\n",
    "GPU_ID = 0\n",
    "USE_GPU = True\n",
    "\n",
    "if tf.config.list_physical_devices('GPU') and USE_GPU:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    gpu_name = gpus[0].name  # You may specify an index if using multiple GPUs\n",
    "    print(f\"Using GPU - {gpu_name}\")\n",
    "    device = '/GPU:0'\n",
    "else:\n",
    "    device = '/CPU:0'\n",
    "\n",
    "with tf.device(device):\n",
    "    pass\n",
    "\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "N_CPU_CORES = multiprocessing.cpu_count()\n",
    "\n",
    "BASE_FOLDER = os.path.join(\n",
    "    \"..\", \"input\", \"tlvmc-parkinsons-freezing-gait-prediction\"\n",
    ")\n",
    "\n",
    "print(f\"Number of CPU cores available: {N_CPU_CORES}\")\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from typing import List, Tuple\n",
    "from models.cnn_models import *\n",
    "import random\n",
    "img_shape = (64, 64)"
   ],
   "id": "3b829d8c6743bafc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU - /physical_device:GPU:0\n",
      "Using device /GPU:0\n",
      "Number of CPU cores available: 12\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T20:45:30.166438Z",
     "start_time": "2024-11-09T20:45:30.155393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomMultiInputDataGenerator(Sequence):\n",
    "    def __init__(self, directories, batch_size=32, image_size=img_shape, shuffle=True, augment=False, num_classes=2, **kwargs):\n",
    "        \"\"\"\n",
    "        directories: List of directories, one for each input branch.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.directories = directories\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.num_classes = num_classes\n",
    "        self.image_paths = self._load_image_paths()\n",
    "        self.samples = len(self.image_paths[0])\n",
    "        \n",
    "        self.datagen = ImageDataGenerator(\n",
    "            rescale=1/255.0,\n",
    "            width_shift_range=0.1 if self.augment else 0,\n",
    "            height_shift_range=0.1 if self.augment else 0\n",
    "        )\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _load_image_paths(self):\n",
    "        # Load image paths for each branch directory\n",
    "        image_paths = []\n",
    "        for directory in self.directories:\n",
    "            branch_image_paths = [os.path.join(directory, fname) for fname in os.listdir(directory) if fname.endswith('.jpg')]\n",
    "            image_paths.append(branch_image_paths)\n",
    "        return image_paths\n",
    "\n",
    "    def _get_class_from_filename(self, filename):\n",
    "        # Extract label from filename assuming a naming convention\n",
    "        class_label = int(filename.split('_')[-1].split('.')[0])\n",
    "        return class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load a batch of images for each branch\n",
    "        batch_image_paths = [paths[index * self.batch_size:(index + 1) * self.batch_size] for paths in self.image_paths]\n",
    "        \n",
    "        # Load and preprocess images for each branch\n",
    "        images_per_branch = []\n",
    "        for branch_paths in batch_image_paths:\n",
    "            images = np.array([img_to_array(load_img(path, target_size=self.image_size)) for path in branch_paths])\n",
    "            if self.augment:\n",
    "                images = np.array([self.datagen.random_transform(image) for image in images])\n",
    "            else:\n",
    "                images = self.datagen.standardize(images)\n",
    "            images_per_branch.append(images)\n",
    "\n",
    "        # Load labels (assuming the same labels for each branch)\n",
    "        labels = np.array([self._get_class_from_filename(os.path.basename(path)) for path in batch_image_paths[0]])\n",
    "        labels = to_categorical(labels, num_classes=self.num_classes)\n",
    "        \n",
    "        return images_per_branch, labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            for branch_paths in self.image_paths:\n",
    "                np.random.shuffle(branch_paths)"
   ],
   "id": "16ef52e3e3aa251b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DEBUG = True\n",
    "\n",
    "class FederatedClient:\n",
    "    def __init__(self, client_id: int, model_fn, train_generator, valid_generator=None):\n",
    "        self.client_id = client_id\n",
    "        self.model = model_fn()\n",
    "        self.train_generator = train_generator\n",
    "        self.valid_generator = valid_generator\n",
    "    \n",
    "    def train(self, global_weights, local_epochs=5):\n",
    "        # Update local model with global weights\n",
    "        self.model.set_weights(global_weights)\n",
    "        if DEBUG:\n",
    "            print(\"train_generator:\")\n",
    "            print(len(self.train_generator[0][1]), self.train_generator.samples)\n",
    "            \n",
    "        # Train the model locally using the generator\n",
    "        history = self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=local_epochs,\n",
    "            validation_data=self.valid_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return self.model.get_weights(), history.history\n",
    "\n",
    "class FederatedServer:\n",
    "    def __init__(self, model_fn):\n",
    "        self.global_model = model_fn()\n",
    "        self.clients = []\n",
    "        \n",
    "    def add_client(self, client: FederatedClient):\n",
    "        self.clients.append(client)\n",
    "    \n",
    "    def aggregate_weights(self, client_weights: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        \"\"\"FedAvg aggregation with sample weighting\"\"\"\n",
    "        # Get number of samples for each client\n",
    "        client_samples = [client.train_generator.samples for client in self.clients]\n",
    "        total_samples = sum(client_samples)\n",
    "        \n",
    "        # Calculate weighted average based on number of samples\n",
    "        weighted_weights = []\n",
    "        for idx, weights in enumerate(client_weights):\n",
    "            weight = client_samples[idx] / total_samples\n",
    "            weighted_weights.append([w * weight for w in weights])\n",
    "        \n",
    "        # Sum up the weighted weights\n",
    "        averaged_weights = [\n",
    "            sum(weights_list) \n",
    "            for weights_list in zip(*weighted_weights)\n",
    "        ]\n",
    "        \n",
    "        return averaged_weights\n",
    "\n",
    "    def evaluate(self, test_generator):\n",
    "        \"\"\"Evaluate the global model on test data\"\"\"\n",
    "        return self.global_model.evaluate(test_generator)\n",
    "\n",
    "\n",
    "def split_data_for_clients(train_generator, num_clients: int) -> List[List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Split image paths into non-overlapping subsets for each client\n",
    "    \n",
    "    Args:\n",
    "        image_paths_list: List of lists of image paths (one list per branch)\n",
    "        num_clients: Number of clients to split data for\n",
    "    \n",
    "    Returns:\n",
    "        List of client datasets, where each client dataset contains lists of paths for each branch\n",
    "    \"\"\"\n",
    "    image_paths_list = train_generator.image_paths\n",
    "    # Ensure all branches have the same number of images\n",
    "    total_samples = len(image_paths_list[0])\n",
    "    assert all(len(paths) == total_samples for paths in image_paths_list)\n",
    "    \n",
    "    # Create indices for splitting\n",
    "    indices = list(range(total_samples))\n",
    "    \n",
    "    if train_generator.shuffle:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    # Calculate samples per client\n",
    "    samples_per_client = total_samples // num_clients\n",
    "    \n",
    "    # Split indices for each client\n",
    "    client_indices = [\n",
    "        indices[i * samples_per_client:(i + 1) * samples_per_client]\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    # Add remaining samples to the last client\n",
    "    if total_samples % num_clients != 0:\n",
    "        remaining = indices[num_clients * samples_per_client:]\n",
    "        client_indices[-1].extend(remaining)\n",
    "    \n",
    "    # Create client datasets\n",
    "    client_datasets = []\n",
    "    for client_idx in client_indices:\n",
    "        client_data = []\n",
    "        for branch_paths in image_paths_list:\n",
    "            client_branch_paths = [branch_paths[i] for i in client_idx]\n",
    "            client_data.append(client_branch_paths)\n",
    "        client_datasets.append(client_data)\n",
    "    \n",
    "    return client_datasets\n",
    "\n",
    "def create_client_generator(base_generator, client_image_paths):\n",
    "    \"\"\"\n",
    "    Create a new generator for a client with specific image paths\n",
    "    \"\"\"\n",
    "    client_generator = CustomMultiInputDataGenerator(\n",
    "        directories=base_generator.directories,\n",
    "        batch_size=base_generator.batch_size,\n",
    "        image_size=base_generator.image_size,\n",
    "        shuffle=base_generator.shuffle,\n",
    "        augment=base_generator.augment,\n",
    "        num_classes=base_generator.num_classes\n",
    "    )\n",
    "    \n",
    "    # Set the client-specific image paths\n",
    "    client_generator.image_paths = client_image_paths\n",
    "    client_generator.samples = len(client_image_paths[0])\n",
    "    \n",
    "    return client_generator\n",
    "\n",
    "\n",
    "def create_federated_learning_system(\n",
    "    num_clients: int,\n",
    "    train_generator,\n",
    "    valid_generator=None,\n",
    "    input_shape1=(64, 64, 3),\n",
    "    input_shape2=(64, 64, 3),\n",
    "    input_shape3=(64, 64, 3),\n",
    "    num_classes=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a federated learning system using data generators\n",
    "    \n",
    "    Args:\n",
    "        num_clients: Number of clients to simulate\n",
    "        train_generator: CustomMultiInputDataGenerator for training\n",
    "        valid_generator: Optional CustomMultiInputDataGenerator for validation\n",
    "        input_shape1/2/3: Input shapes for the three branches\n",
    "        num_classes: Number of output classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def model_fn():\n",
    "        return create_multi_input_cnn(\n",
    "            input_shape1=input_shape1,\n",
    "            input_shape2=input_shape2,\n",
    "            input_shape3=input_shape3\n",
    "        )\n",
    "    \n",
    "    # Initialize server\n",
    "    server = FederatedServer(model_fn)\n",
    "    \n",
    "    # Split data among clients\n",
    "    client_datasets = split_data_for_clients(train_generator, num_clients)\n",
    "    \n",
    "    # Create clients with their specific data\n",
    "    for i, client_image_paths in enumerate(client_datasets):\n",
    "        # Create client-specific generator\n",
    "        client_train_generator = create_client_generator(train_generator, client_image_paths)\n",
    "        \n",
    "        # Create client\n",
    "        client = FederatedClient(\n",
    "            client_id=i,\n",
    "            model_fn=model_fn,\n",
    "            train_generator=client_train_generator,\n",
    "            valid_generator=valid_generator\n",
    "        )\n",
    "        server.add_client(client)\n",
    "        \n",
    "        print(f\"Client {i} created with {client_train_generator.samples} samples\")\n",
    "    \n",
    "    return server\n",
    "\n",
    "def train_federated(\n",
    "    server: FederatedServer,\n",
    "    num_rounds: int,\n",
    "    local_epochs: int,\n",
    "    test_generator=None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Train the model using federated learning\n",
    "    \n",
    "    Args:\n",
    "        server: FederatedServer instance\n",
    "        num_rounds: Number of federated learning rounds\n",
    "        local_epochs: Number of local epochs per client\n",
    "        test_generator: Optional generator for testing global model\n",
    "    \"\"\"\n",
    "    metrics_history = []\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"\\nFederated Learning Round {round_num + 1}/{num_rounds}\")\n",
    "        \n",
    "        # Get current global weights\n",
    "        global_weights = server.global_model.get_weights()\n",
    "        \n",
    "        # Train each client locally\n",
    "        client_weights = []\n",
    "        client_metrics = []\n",
    "        \n",
    "        for client in server.clients:\n",
    "            print(f\"\\nTraining Client {client.client_id + 1}/{len(server.clients)}\")\n",
    "            weights, metrics = client.train(\n",
    "                global_weights,\n",
    "                local_epochs=local_epochs\n",
    "            )\n",
    "            client_weights.append(weights)\n",
    "            client_metrics.append(metrics)\n",
    "        \n",
    "        # Aggregate weights using FedAvg\n",
    "        new_global_weights = server.aggregate_weights(client_weights)\n",
    "        \n",
    "        # Update global model\n",
    "        server.global_model.set_weights(new_global_weights)\n",
    "        \n",
    "        # Evaluate global model if test generator is provided\n",
    "        if test_generator is not None:\n",
    "            print(\"\\nEvaluating global model:\")\n",
    "            test_metrics = server.evaluate(test_generator)\n",
    "            test_results = dict(zip(server.global_model.metrics_names, test_metrics))\n",
    "            print(\"Test metrics:\", test_results)\n",
    "        \n",
    "        # Aggregate training metrics\n",
    "        round_metrics = {\n",
    "            metric: np.mean([client_metric[metric][-1] \n",
    "                           for client_metric in client_metrics])\n",
    "            for metric in client_metrics[0].keys()\n",
    "        }\n",
    "        metrics_history.append(round_metrics)\n",
    "        \n",
    "        # Print round metrics\n",
    "        print(\"\\nRound Training Metrics:\")\n",
    "        for metric, value in round_metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics_history"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T20:50:17.053375Z",
     "start_time": "2024-11-09T20:50:16.955800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_directories = [\"../data/federated_learning_data/AccAP/train\", \"../data/federated_learning_data/AccML/train\", \"../data/federated_learning_data/AccV/train\"]\n",
    "\n",
    "val_directories = [\"../data/federated_learning_data/AccAP/valid\", \"../data/federated_learning_data/AccML/valid\", \"../data/federated_learning_data/AccV/valid\"]\n",
    "\n",
    "train_generator = CustomMultiInputDataGenerator(\n",
    "    directories=train_directories,\n",
    "    batch_size=32,\n",
    "    image_size=img_shape,\n",
    "    augment=False,\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "valid_generator = CustomMultiInputDataGenerator(\n",
    "    directories=val_directories,\n",
    "    batch_size=32,\n",
    "    image_size=img_shape,\n",
    "    augment=False,\n",
    "    num_classes=2\n",
    ")"
   ],
   "id": "bad16b3b6da78324",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "server = create_federated_learning_system(\n",
    "    num_clients=5,\n",
    "    train_generator=train_generator,\n",
    "    valid_generator=valid_generator,\n",
    "    input_shape1=(64, 64, 3),\n",
    "    input_shape2=(64, 64, 3),\n",
    "    input_shape3=(64, 64, 3),\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "# Train using federated learning\n",
    "metrics_history = train_federated(\n",
    "    server,\n",
    "    num_rounds=10,\n",
    "    local_epochs=5,\n",
    "    test_generator=valid_generator\n",
    ")"
   ],
   "id": "a87b00ea2003aa4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T01:09:59.556189Z",
     "start_time": "2024-11-10T01:09:58.311246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_directories = [\"../data/federated_learning_data/AccAP/test\", \"../data/federated_learning_data/AccML/test\", \"../data/federated_learning_data/AccV/test\"]\n",
    "\n",
    "test_generator = CustomMultiInputDataGenerator(\n",
    "    directories=test_directories,\n",
    "    batch_size=32,\n",
    "    image_size=img_shape,\n",
    "    augment=False,\n",
    "    num_classes=2,\n",
    "    shuffle=False\n",
    ")"
   ],
   "id": "ff818aa4ae3c7e77",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T21:25:49.877084Z",
     "start_time": "2024-11-13T21:25:04.475460Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8698641087130295, 'precision': 0.8683679503357472, 'recall': 0.8698641087130295, 'specificity': 0.767056530214425, 'sensitivity': 0.9200571020699501, 'f1_micro': 0.8698641087130295, 'f1_macro': 0.849660627151198, 'f1_weighted': 0.8686129554719567, 'f1_per_class': array([0.79454821, 0.90477305]), 'precision_per_class': array([0.82408377, 0.88998849]), 'recall_per_class': array([0.76705653, 0.9200571 ]), 'true_positives_percentage': 61.82254196642686, 'true_negatives_percentage': 25.163868904876097, 'false_positives_percentage': 7.641886490807353, 'false_negatives_percentage': 5.371702637889688, 'true_positives': 3867, 'true_negatives': 1574, 'false_positives': 478, 'false_negatives': 336}\n"
     ]
    }
   ],
   "execution_count": 15,
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, generator):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(len(generator)):\n",
    "        images, batch_y_true = generator[i]\n",
    "        \n",
    "        batch_predictions = model.predict(images, verbose=0)\n",
    "        \n",
    "        batch_y_pred = np.argmax(batch_predictions, axis=1)\n",
    "        batch_y_true = np.argmax(batch_y_true, axis=1)\n",
    "        \n",
    "        y_true.extend(batch_y_true.flatten())\n",
    "        y_pred.extend(batch_y_pred.flatten())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    total_samples = len(y_true)\n",
    "    \n",
    "    tn_percent = (tn / total_samples) * 100\n",
    "    fp_percent = (fp / total_samples) * 100\n",
    "    fn_percent = (fn / total_samples) * 100\n",
    "    tp_percent = (tp / total_samples) * 100\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'sensitivity': sensitivity,\n",
    "        \n",
    "        'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
    "        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'f1_per_class': f1_score(y_true, y_pred, average=None),\n",
    "        \n",
    "        'precision_per_class': precision_per_class,\n",
    "        'recall_per_class': recall_per_class,\n",
    "        \n",
    "        'true_positives_percentage': tp_percent,\n",
    "        'true_negatives_percentage': tn_percent,\n",
    "        'false_positives_percentage': fp_percent,\n",
    "        'false_negatives_percentage': fn_percent,\n",
    "        \n",
    "        'true_positives': tp,\n",
    "        'true_negatives': tn,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "results = evaluate_model(server.global_model, test_generator)\n",
    "\n",
    "print(results)"
   ],
   "id": "52a00f337f90b263"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
